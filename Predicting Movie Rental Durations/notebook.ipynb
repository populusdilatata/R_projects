{"cells":[{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD based on some features and have approached you for help. They want you to try out some regression models that will help predict the number of days a customer will rent a DVD for. The company wants a model that yields an MSE of 3 or less on a test set. The model you make will help the company become more efficient in inventory planning.\n\nThe data they provided is in the CSV file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Length of the movie being rented, in minutes.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convenience, the reference dummy has already been dropped.","metadata":{},"id":"614a8d7b-890a-4a0c-b03b-6b369dd7b1ff","cell_type":"markdown"},{"source":"# Imports\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(tidymodels)\nlibrary(lubridate)\nlibrary(caret)\nlibrary(glmnet)","metadata":{"executionCancelledAt":null,"executionTime":9821,"lastExecutedAt":1751732372850,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Imports\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(tidymodels)\nlibrary(lubridate)\nlibrary(caret)\nlibrary(glmnet)","outputsMetadata":{"0":{"height":507,"type":"stream"},"1":{"height":57,"type":"stream"},"2":{"height":277,"type":"stream"}},"lastExecutedByKernel":"dcf849a5-6f13-4379-a201-b6e1aa6954eb"},"id":"174731e4-0b1f-42f1-8803-35c72c8d1b83","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":"\nAttaching package: ‘dplyr’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\n\n\nThe following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\n\n\n── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.8     \u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.3.0\n\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mtibble      \u001b[39m 3.2.1\n\u001b[32m✔\u001b[39m \u001b[34mggplot2     \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr       \u001b[39m 1.3.1\n\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.8     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.3.0\n\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.2.0\n\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.1.0\n\u001b[32m✔\u001b[39m \u001b[34mpurrr       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.3.2\n\n── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mscales\u001b[39m::discard()\n\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m  masks \u001b[34mstats\u001b[39m::step()\n\n\nAttaching package: ‘lubridate’\n\n\nThe following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\nLoading required package: lattice\n\n\nAttaching package: ‘caret’\n\n\nThe following objects are masked from ‘package:yardstick’:\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from ‘package:purrr’:\n\n    lift\n\n\nLoading required package: Matrix\n\n\nAttaching package: ‘Matrix’\n\n\nThe following objects are masked from ‘package:tidyr’:\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n"}]},{"source":"# Get the number of rental days\ndf_rental <- read.csv(\"rental_info.csv\")\ndf_rental$rental_date <- ymd_hms(df_rental$rental_date)\ndf_rental$return_date <- ymd_hms(df_rental$return_date)\ndf_rental <- df_rental %>%\n  mutate(rental_length = as.numeric(difftime(return_date, rental_date, units = \"hours\")))\ndf_rental$rental_length_days <- df_rental$rental_length / 24  \n\n# Add variables from the special features column\ndf_rental$deleted_scenes = as.numeric(grepl(\"Deleted Scenes\", df_rental$special_features))\ndf_rental$behind_the_scenes = as.numeric(grepl(\"Behind the Scenes\", df_rental$special_features))\n\n# Keep relevant columns\nX = df_rental\nX$return_date = NULL\nX$rental_date = NULL\nX$rental_length = NULL\nX$special_features = NULL\n\n# Perform a train-test split\nset.seed(9)\nsplit <- initial_split(X, prop = 0.8) \nX_train <- training(split)\nX_test <- testing(split)\ny_train <- as.numeric(X_train$rental_length_days)\ny_test <- as.numeric(X_test$rental_length_days)\nX_train$rental_length_days = NULL\nX_test$rental_length_days = NULL\n\n# Center and scale the training and testing sets: this standardization makes the model less sensitive to the scale of features\npreProcValues <- preProcess(X_train, method = c(\"center\", \"scale\"))\nX_train <- predict(preProcValues, X_train)\nX_test <- predict(preProcValues, X_test)\n\n# Perform feature selection: here we are using the Lasso model to identify the features to be subsequently used in other regression models\nlasso_model <- glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = 0.3)\n# Extract coefficients at the specified lambda value\nnon_zero_coef <- coef(lasso_model, s = 0.3)[,1]\n# Exclude the intercept\nnon_zero_coef <- non_zero_coef[2:length(non_zero_coef)]\n# Select non-zero coefficients\nfeatures_selected <- names(non_zero_coef[non_zero_coef != 0])\nX_train_selected <- X_train[, features_selected, drop = FALSE]\nX_test_selected <- X_test[, features_selected, drop = FALSE]\n\n# Try a couple of models and choose the best MSE score\n# Linear Regression\nlm_model <- lm(y_train ~ ., data = as.data.frame(X_train_selected))\npredictions <- predict(lm_model, newdata = X_test)\nmse_lr <- mean((predictions - y_test) ^ 2)\nprint(paste(\"Mean Squared Error:\", mse_lr))\n# Decision Tree: train the tree model using cross-validation to select the best tree complexity\ndt_model <- train(x = as.matrix(X_train), y = y_train, method = \"rpart\",\n                  trControl = trainControl(method = \"cv\", number = 10),\n                  tuneLength = 10)\ndt_pred <- predict(dt_model, newdata = X_test)\nmse_dt <- mean((dt_pred - y_test)^2)\nbest_mse = mse_dt\nbest_model = dt_model","metadata":{"executionCancelledAt":null,"executionTime":7677,"lastExecutedAt":1751732380527,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get the number of rental days\ndf_rental <- read.csv(\"rental_info.csv\")\ndf_rental$rental_date <- ymd_hms(df_rental$rental_date)\ndf_rental$return_date <- ymd_hms(df_rental$return_date)\ndf_rental <- df_rental %>%\n  mutate(rental_length = as.numeric(difftime(return_date, rental_date, units = \"hours\")))\ndf_rental$rental_length_days <- df_rental$rental_length / 24  \n\n# Add variables from the special features column\ndf_rental$deleted_scenes = as.numeric(grepl(\"Deleted Scenes\", df_rental$special_features))\ndf_rental$behind_the_scenes = as.numeric(grepl(\"Behind the Scenes\", df_rental$special_features))\n\n# Keep relevant columns\nX = df_rental\nX$return_date = NULL\nX$rental_date = NULL\nX$rental_length = NULL\nX$special_features = NULL\n\n# Perform a train-test split\nset.seed(9)\nsplit <- initial_split(X, prop = 0.8) \nX_train <- training(split)\nX_test <- testing(split)\ny_train <- as.numeric(X_train$rental_length_days)\ny_test <- as.numeric(X_test$rental_length_days)\nX_train$rental_length_days = NULL\nX_test$rental_length_days = NULL\n\n# Center and scale the training and testing sets: this standardization makes the model less sensitive to the scale of features\npreProcValues <- preProcess(X_train, method = c(\"center\", \"scale\"))\nX_train <- predict(preProcValues, X_train)\nX_test <- predict(preProcValues, X_test)\n\n# Perform feature selection: here we are using the Lasso model to identify the features to be subsequently used in other regression models\nlasso_model <- glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = 0.3)\n# Extract coefficients at the specified lambda value\nnon_zero_coef <- coef(lasso_model, s = 0.3)[,1]\n# Exclude the intercept\nnon_zero_coef <- non_zero_coef[2:length(non_zero_coef)]\n# Select non-zero coefficients\nfeatures_selected <- names(non_zero_coef[non_zero_coef != 0])\nX_train_selected <- X_train[, features_selected, drop = FALSE]\nX_test_selected <- X_test[, features_selected, drop = FALSE]\n\n# Try a couple of models and choose the best MSE score\n# Linear Regression\nlm_model <- lm(y_train ~ ., data = as.data.frame(X_train_selected))\npredictions <- predict(lm_model, newdata = X_test)\nmse_lr <- mean((predictions - y_test) ^ 2)\nprint(paste(\"Mean Squared Error:\", mse_lr))\n# Decision Tree: train the tree model using cross-validation to select the best tree complexity\ndt_model <- train(x = as.matrix(X_train), y = y_train, method = \"rpart\",\n                  trControl = trainControl(method = \"cv\", number = 10),\n                  tuneLength = 10)\ndt_pred <- predict(dt_model, newdata = X_test)\nmse_dt <- mean((dt_pred - y_test)^2)\nbest_mse = mse_dt\nbest_model = dt_model","lastExecutedByKernel":"dcf849a5-6f13-4379-a201-b6e1aa6954eb","outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":59,"type":"stream"}}},"id":"20ffd787-930a-4909-a403-6a7a82956dd7","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"[1] \"Mean Squared Error: 2.74078104376894\"\n"},{"output_type":"stream","name":"stderr","text":"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n“There were missing values in resampled performance measures.”\n"}]}],"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}